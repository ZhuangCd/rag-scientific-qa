{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aee082d",
   "metadata": {},
   "source": [
    "# Simple RAG for Scientific Papers\n",
    "\n",
    "This notebook implements a Simple (Naive) RAG Model for answering questions based on scientific literature.\n",
    "\n",
    "**Task:** Retrieval-Augmented Generation  \n",
    "**Dataset:** 200 Scientific Papers (JSON format)  \n",
    "\n",
    "**Features:**\n",
    "- ChromaDB for vector storage\n",
    "- Overlapping chunking (window size 150, overlap 50)\n",
    "- Sentence Transformers for embeddings\n",
    "- Source document references for transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3509e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Install dependencies ---\n",
    "!pip install chromadb sentence-transformers transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load scientific papers from JSON files ---\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "papers_dir = \"../papers_json_3/papers_json_3\"\n",
    "\n",
    "def load_papers(papers_dir, max_papers=200):\n",
    "    \"\"\"Load scientific papers from JSON files.\"\"\"\n",
    "    corpus = []\n",
    "    files = sorted([f for f in os.listdir(papers_dir) if f.endswith('.json')])[:max_papers]\n",
    "    \n",
    "    for filename in tqdm(files, desc=\"Loading papers\"):\n",
    "        filepath = os.path.join(papers_dir, filename)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                paper = json.load(f)\n",
    "                \n",
    "            corpus.append({\n",
    "                \"article_id\": paper.get(\"article_id\", filename.replace(\".json\", \"\")),\n",
    "                \"abstract\": paper.get(\"abstract\", \"\"),\n",
    "                \"article\": paper.get(\"article\", \"\"),\n",
    "                \"section_names\": paper.get(\"section_names\", []),\n",
    "                \"filename\": filename\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "papers_corpus = load_papers(papers_dir)\n",
    "print(f\"Loaded {len(papers_corpus)} papers\")\n",
    "print(f\"Sample paper: {papers_corpus[0]['article_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f876eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Overlapping chunking function ---\n",
    "# Apply overlapping chunking: window size 150 tokens, overlap 50 tokens\n",
    "# Only chunk text segments longer than 100 tokens\n",
    "\n",
    "def chunk_text(text, chunk_size=150, overlap=50, min_length=100):\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks.\n",
    "    - chunk_size: window size in tokens (words)\n",
    "    - overlap: number of overlapping tokens between chunks\n",
    "    - min_length: minimum text length (in tokens) to apply chunking\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    \n",
    "    # If text is shorter than min_length, return as single chunk\n",
    "    if len(words) <= min_length:\n",
    "        return [text] if words else []\n",
    "    \n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        i += chunk_size - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def build_chunks(corpus):\n",
    "    \"\"\"Build chunks from the paper corpus with metadata.\"\"\"\n",
    "    chunk_texts = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    \n",
    "    for paper in tqdm(corpus, desc=\"Chunking papers\"):\n",
    "        article_id = paper[\"article_id\"]\n",
    "        \n",
    "        # Combine abstract and article for chunking\n",
    "        full_text = paper[\"abstract\"] + \"\\n\\n\" + paper[\"article\"]\n",
    "        chunks = chunk_text(full_text, chunk_size=150, overlap=50)\n",
    "        \n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            chunk_texts.append(chunk)\n",
    "            metadatas.append({\n",
    "                \"article_id\": article_id,\n",
    "                \"chunk_idx\": idx,\n",
    "                \"source\": f\"{article_id}_chunk_{idx}\",\n",
    "                \"filename\": paper[\"filename\"]\n",
    "            })\n",
    "            ids.append(f\"{article_id}_chunk_{idx}\")\n",
    "    \n",
    "    return chunk_texts, metadatas, ids\n",
    "\n",
    "chunk_texts, metadatas, ids = build_chunks(papers_corpus)\n",
    "print(f\"Total chunks created: {len(chunk_texts)}\")\n",
    "print(f\"Sample chunk metadata: {metadatas[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Initialize embedding model ---\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Using all-MiniLM-L6-v2 for embeddings (same as DSK821 example)\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(f\"Embedding model loaded: all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d78c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Initialize ChromaDB and create collection ---\n",
    "import chromadb\n",
    "\n",
    "persist_dir = \"scientific_papers_rag_db\"\n",
    "\n",
    "# Create persistent client\n",
    "client = chromadb.PersistentClient(path=persist_dir)\n",
    "\n",
    "# Create or get collection\n",
    "collection = client.get_or_create_collection(\"scientific_papers_rag\")\n",
    "print(f\"ChromaDB collection created/loaded: {collection.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df769ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Embed chunks and add to ChromaDB ---\n",
    "# Only add if collection is empty (to avoid duplicates on re-run)\n",
    "\n",
    "if collection.count() == 0:\n",
    "    print(\"Embedding and indexing chunks...\")\n",
    "    \n",
    "    # Embed in batches to avoid memory issues\n",
    "    batch_size = 100\n",
    "    for i in tqdm(range(0, len(chunk_texts), batch_size), desc=\"Indexing\"):\n",
    "        batch_texts = chunk_texts[i:i + batch_size]\n",
    "        batch_metas = metadatas[i:i + batch_size]\n",
    "        batch_ids = ids[i:i + batch_size]\n",
    "        \n",
    "        # Compute embeddings\n",
    "        batch_embeddings = embedder.encode(batch_texts, show_progress_bar=False).tolist()\n",
    "        \n",
    "        # Add to collection\n",
    "        collection.add(\n",
    "            documents=batch_texts,\n",
    "            embeddings=batch_embeddings,\n",
    "            metadatas=batch_metas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "    \n",
    "    print(f\"Indexed {collection.count()} chunks\")\n",
    "else:\n",
    "    print(f\"Collection already has {collection.count()} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b54304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Simple retrieval function ---\n",
    "def retrieve(query, k=3):\n",
    "    \"\"\"\n",
    "    Retrieve top-k most similar chunks for a given query.\n",
    "    Returns documents with their metadata (source references).\n",
    "    \"\"\"\n",
    "    q_emb = embedder.encode([query]).tolist()[0]\n",
    "    results = collection.query(\n",
    "        query_embeddings=[q_emb],\n",
    "        n_results=k\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"documents\": results[\"documents\"][0],\n",
    "        \"metadatas\": results[\"metadatas\"][0],\n",
    "        \"ids\": results[\"ids\"][0]\n",
    "    }\n",
    "\n",
    "# Test retrieval\n",
    "test_results = retrieve(\"random walk on networks\")\n",
    "print(\"Test query: 'random walk on networks'\")\n",
    "print(f\"Retrieved {len(test_results['documents'])} chunks\")\n",
    "for i, (doc, meta) in enumerate(zip(test_results['documents'][:2], test_results['metadatas'][:2])):\n",
    "    print(f\"\\n[{i+1}] Source: {meta['article_id']} (chunk {meta['chunk_idx']})\")\n",
    "    print(f\"Text preview: {doc[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e457bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Load LLM (Phi-3 Mini for generation) ---\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Use GPU if available, otherwise CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Build context with citations ---\n",
    "def build_context_with_citations(retrieved_docs, limit_chars=3500):\n",
    "    \"\"\"\n",
    "    Build context string with source citations.\n",
    "    Each chunk is labeled with its source reference.\n",
    "    \"\"\"\n",
    "    context = []\n",
    "    total = 0\n",
    "    \n",
    "    for i, (doc, meta) in enumerate(zip(retrieved_docs[\"documents\"], retrieved_docs[\"metadatas\"]), 1):\n",
    "        header = f\"[{i}] Source: {meta['article_id']} (chunk {meta['chunk_idx']})\"\n",
    "        block = f\"{header}\\n{doc[:900]}\\n\"\n",
    "        \n",
    "        if total + len(block) > limit_chars:\n",
    "            break\n",
    "        \n",
    "        context.append(block)\n",
    "        total += len(block)\n",
    "    \n",
    "    return \"\\n\".join(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47644a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Simple RAG answer generation ---\n",
    "def rag_answer(query, k=3):\n",
    "    \"\"\"\n",
    "    Generate an answer using RAG.\n",
    "    - Retrieves relevant chunks\n",
    "    - Builds context with citations\n",
    "    - Generates answer using LLM\n",
    "    - Returns answer with source references\n",
    "    \"\"\"\n",
    "    # Retrieve relevant chunks\n",
    "    retrieved = retrieve(query, k=k)\n",
    "    context = build_context_with_citations(retrieved)\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = f\"\"\"You are a helpful assistant answering questions based ONLY on the following scientific paper excerpts.\n",
    "Use citations like [1], [2] referring to the sources provided.\n",
    "If the context doesn't contain enough information to answer, say so.\n",
    "\n",
    "==================== SOURCES ====================\n",
    "{context}\n",
    "=================================================\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer with citations:\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate answer\n",
    "    tokens = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**tokens, max_new_tokens=250, do_sample=False)\n",
    "    full_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract answer part\n",
    "    if \"Answer with citations:\" in full_response:\n",
    "        answer = full_response.split(\"Answer with citations:\")[-1].strip()\n",
    "    else:\n",
    "        answer = full_response\n",
    "    \n",
    "    # Return answer with source references\n",
    "    sources = [meta['article_id'] for meta in retrieved['metadatas']]\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": sources,\n",
    "        \"retrieved_docs\": retrieved\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. Test the Simple RAG system ---\n",
    "print(\"Testing Simple RAG System\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_queries = [\n",
    "    \"What is a random walk on a network?\",\n",
    "    \"How do biased random walks work?\",\n",
    "    \"What is entropy rate in the context of random walks?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQUESTION: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    result = rag_answer(query)\n",
    "    print(f\"ANSWER: {result['answer']}\")\n",
    "    print(f\"SOURCES: {', '.join(result['sources'])}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b7dff",
   "metadata": {},
   "source": [
    "## 15 Evaluation Questions\n",
    "\n",
    "Below are 15 questions for evaluating the RAG system:\n",
    "- **5 Simple Questions** (basic concepts)\n",
    "- **5 Medium Questions** (require understanding of relationships)\n",
    "- **5 Domain-Specific Detailed Questions** (technical depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788acfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 12. Define 15 Evaluation Questions ---\n",
    "\n",
    "evaluation_questions = {\n",
    "    \"simple\": [\n",
    "        {\n",
    "            \"question\": \"What is a random walk on a graph?\",\n",
    "            \"expected_answer\": \"A random walk is a stochastic process where a walker moves between nodes of a graph by randomly selecting one of the edges connected to the current node.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is a multiplex network?\",\n",
    "            \"expected_answer\": \"A multiplex network is a multi-layer network where nodes can be connected through different types of relationships organized in distinct and interacting layers.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the overlapping adjacency matrix?\",\n",
    "            \"expected_answer\": \"The overlapping adjacency matrix accounts for the total number of connections between two nodes across all layers of a multiplex network.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is an embedding in machine learning?\",\n",
    "            \"expected_answer\": \"An embedding is a dense vector representation of data (like words, nodes, or documents) in a continuous vector space that captures semantic similarities.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is ChromaDB used for?\",\n",
    "            \"expected_answer\": \"ChromaDB is a vector database used for storing embeddings and performing similarity search for retrieval-augmented generation systems.\"\n",
    "        }\n",
    "    ],\n",
    "    \"medium\": [\n",
    "        {\n",
    "            \"question\": \"How does the structure of a network affect random walk dynamics?\",\n",
    "            \"expected_answer\": \"Network structure affects random walks through degree distributions, correlations between nodes, and the presence of hubs. Heterogeneous degree distributions and degree-degree correlations impact the stationary probability distribution and mixing properties.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the relationship between entropy rate and walk dispersiveness?\",\n",
    "            \"expected_answer\": \"Entropy rate measures the mixedness or dispersiveness of a walk. Higher entropy rate means the walk can explore remote regions of a graph within fewer steps, with all trajectories being more equiprobable.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How do inter-layer degree correlations affect multiplex random walks?\",\n",
    "            \"expected_answer\": \"Inter-layer degree correlations determine whether hubs at one layer are also hubs at other layers. Positive correlations (similar degree sequences across layers) affect the achievable entropy rate and stationary probability distribution.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the difference between extensive and intensive bias functions?\",\n",
    "            \"expected_answer\": \"Extensive bias functions depend on node degrees at each layer (parameters scale with layer count), while intensive bias functions depend on intrinsically multiplex properties like overlapping degree and participation coefficient (fixed parameters regardless of layers).\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How does edge overlap affect network exploration efficiency?\",\n",
    "            \"expected_answer\": \"High edge overlap (redundant connections across layers) reduces walk dispersiveness and increases heterogeneity in visiting probability. Lower overlap allows more efficient exploration but may reduce robustness.\"\n",
    "        }\n",
    "    ],\n",
    "    \"detailed\": [\n",
    "        {\n",
    "            \"question\": \"What is the mathematical expression for the stationary probability distribution of biased random walks on multiplex networks?\",\n",
    "            \"expected_answer\": \"The stationary probability is π_i* = (o_i * f(i)) / Σ_j(o_j * f(j)), where o_i is the overlapping degree and f(i) is the biasing function value for node i.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How is the participation coefficient defined and what does it measure in multiplex networks?\",\n",
    "            \"expected_answer\": \"The participation coefficient P_i = M/(M-1) * [1 - Σ_α(k_i^[α]/o_i)²] measures how homogeneously a node's edges are distributed across layers. P_i ≈ 1 for truly multiplex nodes with equal degree across layers, P_i ≈ 0 for focused nodes.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the theoretical upper bound of entropy rate for random walks on multiplex networks?\",\n",
    "            \"expected_answer\": \"The maximum entropy rate is log(λ₁), where λ₁ is the maximum eigenvalue of the overlapping adjacency matrix. This represents the case where all trajectories of the same length have equal probability.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How do additive and multiplicative degree-biased walks differ in their transition probabilities?\",\n",
    "            \"expected_answer\": \"Additive walks use transition probabilities based on Σ_α(k_j^[α])^b_α while multiplicative walks use Π_α(k_j^[α])^b_α, where k_j^[α] is the degree at layer α and b_α are bias exponents.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What trade-off exists between dispersiveness and robustness in airline transportation multiplex networks?\",\n",
    "            \"expected_answer\": \"Real-world airline networks show higher edge overlap than random models, sacrificing dispersiveness for robustness to link failures. This results in lower maximum entropy rate and more heterogeneous visiting probability compared to randomized networks.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(\"Evaluation Questions Summary:\")\n",
    "print(f\"- Simple questions: {len(evaluation_questions['simple'])}\")\n",
    "print(f\"- Medium questions: {len(evaluation_questions['medium'])}\")\n",
    "print(f\"- Detailed questions: {len(evaluation_questions['detailed'])}\")\n",
    "print(f\"- Total: {sum(len(v) for v in evaluation_questions.values())} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b28319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 13. Run evaluation on all 15 questions ---\n",
    "def run_evaluation(questions_dict, rag_func):\n",
    "    \"\"\"\n",
    "    Run the RAG system on all evaluation questions.\n",
    "    Returns results with answers and sources for each question.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for difficulty, questions in questions_dict.items():\n",
    "        results[difficulty] = []\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"  {difficulty.upper()} QUESTIONS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, q in enumerate(questions, 1):\n",
    "            print(f\"\\n[{difficulty.upper()} Q{i}] {q['question']}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Get RAG answer\n",
    "            result = rag_func(q['question'], k=3)\n",
    "            \n",
    "            print(f\"RAG ANSWER: {result['answer']}\")\n",
    "            print(f\"SOURCES: {', '.join(result['sources'])}\")\n",
    "            print(f\"EXPECTED: {q['expected_answer'][:200]}...\")\n",
    "            \n",
    "            results[difficulty].append({\n",
    "                \"question\": q['question'],\n",
    "                \"expected_answer\": q['expected_answer'],\n",
    "                \"rag_answer\": result['answer'],\n",
    "                \"sources\": result['sources']\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation (uncomment to execute - may take time)\n",
    "# evaluation_results = run_evaluation(evaluation_questions, rag_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77871e42",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Helper functions for reloading the database and interactive querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63af521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 14. Reload database (for subsequent runs) ---\n",
    "# Use this cell to reload the existing database without re-indexing\n",
    "\n",
    "def reload_database():\n",
    "    \"\"\"Reload the existing ChromaDB database.\"\"\"\n",
    "    import chromadb\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    persist_dir = \"scientific_papers_rag_db\"\n",
    "    client = chromadb.PersistentClient(path=persist_dir)\n",
    "    collection = client.get_collection(\"scientific_papers_rag\")\n",
    "    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    print(f\"Loaded collection with {collection.count()} chunks\")\n",
    "    return client, collection, embedder\n",
    "\n",
    "# Uncomment to reload:\n",
    "# client, collection, embedder = reload_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e466c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 15. Interactive query function ---\n",
    "def ask(question, k=3, show_sources=True):\n",
    "    \"\"\"\n",
    "    Interactive function to ask questions to the RAG system.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to ask\n",
    "        k: Number of chunks to retrieve\n",
    "        show_sources: Whether to display source information\n",
    "    \"\"\"\n",
    "    result = rag_answer(question, k=k)\n",
    "    \n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    \n",
    "    if show_sources:\n",
    "        print(f\"\\nSources:\")\n",
    "        for i, (source, meta) in enumerate(zip(result['sources'], result['retrieved_docs']['metadatas']), 1):\n",
    "            print(f\"  [{i}] {source} (chunk {meta['chunk_idx']})\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# ask(\"What are biased random walks?\")\n",
    "# ask(\"How does entropy rate relate to network exploration?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 16. Display corpus statistics ---\n",
    "def display_corpus_stats():\n",
    "    \"\"\"Display statistics about the indexed corpus.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CORPUS STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total papers loaded: {len(papers_corpus)}\")\n",
    "    print(f\"Total chunks indexed: {collection.count()}\")\n",
    "    print(f\"Average chunks per paper: {collection.count() / len(papers_corpus):.1f}\")\n",
    "    print(f\"Chunking parameters: window=150 tokens, overlap=50 tokens\")\n",
    "    print(f\"Embedding model: all-MiniLM-L6-v2\")\n",
    "    print(f\"LLM model: microsoft/Phi-3-mini-4k-instruct\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "display_corpus_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-scientific-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
