{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41125219",
   "metadata": {},
   "source": [
    "# Advanced RAG for Scientific Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f5eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# print(\"TF:\", tf.__version__)\n",
    "# print(\"Devices:\", tf.config.list_physical_devices())\n",
    "# print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2ced6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uv pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f14054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 papers\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load scientific papers from JSON ---\n",
    "import json\n",
    "import os\n",
    "\n",
    "papers_dir = \"../papers_json_3\"\n",
    "\n",
    "corpus = []\n",
    "files = sorted([f for f in os.listdir(papers_dir) if f.endswith('.json')])[:200]\n",
    "\n",
    "for filename in files:\n",
    "    with open(os.path.join(papers_dir, filename), 'r', encoding='utf-8') as f:\n",
    "        paper = json.load(f)\n",
    "    corpus.append({\n",
    "        \"article_id\": paper.get(\"article_id\", filename.replace(\".json\", \"\")),\n",
    "        \"text\": paper.get(\"abstract\", \"\") + \"\\n\\n\" + paper.get(\"article\", \"\")\n",
    "    })\n",
    "\n",
    "print(f\"Loaded {len(corpus)} papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d837275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 3830\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Improved Chunking Strategy (larger chunks, more overlap) ---\n",
    "'''\n",
    "Advanced chunking: chunk_size=450 words, overlap=100 words\n",
    "Larger chunks preserve more context for scientific papers\n",
    "'''\n",
    "def chunk_text(text, chunk_size=450, overlap=100):\n",
    "    words = text.split()\n",
    "    if len(words) <= 100:\n",
    "        return [text] if words else []\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        i += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# Build chunks with metadata\n",
    "chunk_texts, metadatas, ids = [], [], []\n",
    "\n",
    "for paper in corpus:\n",
    "    chunks = chunk_text(paper[\"text\"])\n",
    "    for idx, ch in enumerate(chunks):\n",
    "        chunk_texts.append(ch)\n",
    "        metadatas.append({\"article_id\": paper[\"article_id\"], \"chunk_idx\": idx})\n",
    "        ids.append(f'{paper[\"article_id\"]}_chunk_{idx}')\n",
    "\n",
    "print(f\"Total chunks: {len(chunk_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c9fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Initialize ChromaDB ---\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"scientific_rag_db\")\n",
    "collection = client.get_or_create_collection(\"scientific_papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be9fccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wk/Desktop/nlp_new/rag-scientific-qa/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding and indexing 3830 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 8/8 [01:10<00:00,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 3830 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Embed and index chunks with BAAI model ---\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Using BAAI/bge-base-en-v1.5 - state-of-the-art for retrieval\n",
    "embedder = SentenceTransformer(\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "if collection.count() == 0:\n",
    "    print(f\"Embedding and indexing {len(chunk_texts)} chunks...\")\n",
    "    \n",
    "    # Embed and add in batches (ChromaDB has max batch size ~5000)\n",
    "    batch_size = 500\n",
    "    for i in tqdm(range(0, len(chunk_texts), batch_size), desc=\"Indexing\"):\n",
    "        batch_texts = chunk_texts[i:i + batch_size]\n",
    "        batch_metas = metadatas[i:i + batch_size]\n",
    "        batch_ids = ids[i:i + batch_size]\n",
    "        \n",
    "        batch_embs = embedder.encode(batch_texts, show_progress_bar=False).tolist()\n",
    "        \n",
    "        collection.add(\n",
    "            documents=batch_texts,\n",
    "            embeddings=batch_embs,\n",
    "            metadatas=batch_metas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "    \n",
    "    print(f\"Indexed {collection.count()} chunks\")\n",
    "else:\n",
    "    print(f\"Collection already has {collection.count()} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b2bf673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] article_1 (chunk 5)\n",
      "    not be directly mapped on an equivalent walk on the aggregated graph . _ stationary probability distribution . _ starting from the one - step transiti...\n",
      "\n",
      "[2] article_1 (chunk 0)\n",
      "    efficient techniques to navigate networks with local information are fundamental to sample large - scale online social systems and to retrieve resourc...\n",
      "\n",
      "[3] article_102 (chunk 42)\n",
      "    and sons , 2008 , xv+352 pages . s. janson , t. uczak , t. turova , and t. vallier . bootstrap percolation on the random graph @xmath858 . , 22(5):198...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Basic Retrieval function ---\n",
    "def retrieve(query, k=3):\n",
    "    q_emb = embedder.encode([query]).tolist()[0]\n",
    "    results = collection.query(query_embeddings=[q_emb], n_results=k)\n",
    "    return results[\"documents\"][0], results[\"metadatas\"][0], results[\"ids\"][0]\n",
    "\n",
    "# Test retrieval\n",
    "docs, metas, doc_ids = retrieve(\"random walk on networks\")\n",
    "for i, (doc, meta) in enumerate(zip(docs, metas)):\n",
    "    print(f\"[{i+1}] {meta['article_id']} (chunk {meta['chunk_idx']})\")\n",
    "    print(f\"    {doc[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9570c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model loaded: Qwen/Qwen2.5-1.5B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Load LLM ---\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Use GPU if available, otherwise CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "print(f\"Model loaded: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "372509d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Multi-Query Rewriting ---\n",
    "def generate_alternative_queries(question, n_queries=3):\n",
    "    prompt = (\n",
    "        f\"Rewrite the following question into {n_queries} alternative search queries, \"\n",
    "        f\"each on a new line:\\n\\nQuestion: {question}\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    out = model.generate(**inputs, max_new_tokens=150)\n",
    "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    lines = [l.strip(\"-• \").strip() for l in text.split(\"\\n\") if l.strip()]\n",
    "    lines = [l for l in lines if question.lower() not in l.lower()]\n",
    "\n",
    "    return lines[:n_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05755576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Multi-Query Retrieval with Deduplication ---\n",
    "def retrieve_multi_query(question, k_per_query=3, n_queries=3):\n",
    "    mq = generate_alternative_queries(question, n_queries=n_queries)\n",
    "    all_qs = [question] + mq\n",
    "\n",
    "    seen = set()\n",
    "    results_list = []\n",
    "\n",
    "    for q in all_qs:\n",
    "        q_emb = embedder.encode([q]).tolist()[0]\n",
    "        result = collection.query(\n",
    "            query_embeddings=[q_emb],\n",
    "            n_results=k_per_query\n",
    "        )\n",
    "\n",
    "        for doc_id, doc, meta in zip(result[\"ids\"][0], result[\"documents\"][0], result[\"metadatas\"][0]):\n",
    "            if doc_id not in seen:\n",
    "                seen.add(doc_id)\n",
    "                results_list.append({\"id\": doc_id, \"text\": doc, \"metadata\": meta})\n",
    "\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ab443fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Context Building with Character Limits ---\n",
    "def build_context_with_limits(docs, limit_chars=3500):\n",
    "    context = []\n",
    "    total = 0\n",
    "    for i, d in enumerate(docs, 1):\n",
    "        header = f\"[{i}] Source: {d['metadata']['article_id']} (chunk {d['metadata']['chunk_idx']})\"\n",
    "        block = f\"{header}\\n{d['text'][:900]}\\n\"\n",
    "        if total + len(block) > limit_chars:\n",
    "            break\n",
    "        context.append(block)\n",
    "        total += len(block)\n",
    "    return \"\\n\".join(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e40c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Advanced RAG Answer Generation ---\n",
    "def rag_answer(query, use_multi_query=True):\n",
    "    if use_multi_query:\n",
    "        retrieved = retrieve_multi_query(query)\n",
    "        context = build_context_with_limits(retrieved)\n",
    "        sources = [d['metadata']['article_id'] for d in retrieved]\n",
    "    else:\n",
    "        docs, metas, _ = retrieve(query)\n",
    "        context_parts = []\n",
    "        for i, (doc, meta) in enumerate(zip(docs, metas), 1):\n",
    "            context_parts.append(f\"[{i}] Source: {meta['article_id']}\\n{doc[:900]}\")\n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        sources = [meta['article_id'] for meta in metas]\n",
    "\n",
    "    prompt = f\"\"\"You are a helpful assistant answering based ONLY on the following scientific paper excerpts.\n",
    "Use citations like [1], [2] referring to the sources provided.\n",
    "\n",
    "==================== SOURCES ====================\n",
    "{context}\n",
    "=================================================\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer with citations:\n",
    "\"\"\"\n",
    "    tokens = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**tokens, max_new_tokens=250, do_sample=False)\n",
    "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract just the answer part\n",
    "    if \"Answer with citations:\" in answer:\n",
    "        answer = answer.split(\"Answer with citations:\")[-1].strip()\n",
    "    \n",
    "    return answer, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a65dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:  What is a random walk in the context of a network? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANSWER: A random walk in the context of a network refers to a process where a walker moves from one node to another, typically according to some set of rules or probabilities, without any specific direction or goal. The movement is stochastic, meaning it follows a probabilistic path rather than a deterministic one. In the context of the provided excerpt, a random walk involves a walker moving from one node to another based on certain transition probabilities, which can be influenced by various factors such as the topology of the network and the properties of neighboring nodes. This type of movement is often used to model diffusion processes, exploratory behavior, or other phenomena within complex networks. [Source: article_1 (chunk 5)]\n",
      "\n",
      "SOURCES: article_63, article_93, article_36, article_1\n",
      "================================================================================\n",
      "QUESTION:  What is meant by a multiplex (multi-layer) network? \n",
      "\n",
      "ANSWER: A multiplex (multi-layer) network refers to a network composed of multiple interconnected layers, each representing different types or aspects of relationships among entities. In such networks, nodes may connect to each other through various types of interactions or attributes, leading to a complex web of connections that reflects diverse dynamics and behaviors. The key characteristics include:\n",
      "\n",
      "- **Multiple Layers**: Each layer represents distinct sets of relationships or attributes, such as social ties, economic transactions, or communication channels.\n",
      "- **Inter-Layer Correlations**: Nodes within different layers often exhibit correlated behavior due to shared underlying mechanisms or constraints.\n",
      "- **Edge Overlap**: Edges connecting nodes across different layers contribute to the overall connectivity pattern of the network.\n",
      "- **Efficient Exploration**: Multiplex networks allow for more efficient exploration compared to simpler networks because they provide a structured way to navigate through multiple layers simultaneously.\n",
      "- **Robustness**: By maintaining a balance between efficiency and robustness, multiplex networks can better withstand perturbations while still providing valuable insights into their underlying structures and dynamics.\n",
      "\n",
      "These features make multiplex networks particularly useful for studying complex systems where interactions are multi-faceted and interconnected. [Source: [1]]\n",
      "\n",
      "SOURCES: article_103, article_63, article_1, article_93, article_36\n",
      "================================================================================\n",
      "QUESTION:  What does the term stationary probability distribution refer to? \n",
      "\n",
      "ANSWER: According to the source material, the stationary probability distribution of biased walks on multiplex networks is derived using a method that involves starting from the one-step transition probability given in equation [eq:walk]. From this, closed-form expressions for various asymptotic properties of the walk are derived. Following an approach similar to that used in reference [@cite], the stationary probability distribution $\\pi$ of biased walks on multiplex networks is shown to be analyt\n",
      "\n",
      "SOURCES: article_146, article_63, article_112, article_1, article_119, article_126, article_93, article_67, article_36\n",
      "================================================================================\n",
      "QUESTION:  What are scalar perturbations in cosmology? \n",
      "\n",
      "ANSWER: Scalar perturbations in cosmology refer to small variations or fluctuations in the density, temperature, or other physical properties of the universe at different points. These perturbations arise due to quantum fluctuations in the early universe and have played a crucial role in shaping the large-scale structure of the cosmos. They include both gravitational waves and non-gravitational effects, such as cosmic microwave background radiation anisotropies and primordial density fluctuations. Understanding scalar perturbations is essential for testing cosmological models and predicting the fate of the universe. [1]\n",
      "\n",
      "[1] Source: article_23 (chunk 2) [2]\n",
      "scalar perturbations in cosmology refer to small variations or fluctuations in the density, temperature, or other physical properties of the universe at different points. these perturbations arise due to quantum fluctuations in the early universe and have played a crucial role in shaping the large-scale structure of the cosmos. they include both gravitational waves and non-gravitational effects, such as cosmic microwave background radiation anisotropies and primordial density fluctuations. understanding scalar perturbations is essential for testing cosmological models and predicting the fate of the universe. [1]\n",
      "\n",
      "SOURCES: article_63, article_23, article_2, article_71, article_93, article_36\n",
      "================================================================================\n",
      "QUESTION:  What physical system do the airline transportation networks represent in the corpus? \n",
      "\n",
      "ANSWER: The study relates to the optimization of transportation systems by focusing on the efficiency and accessibility aspects of these systems. It examines how airlines ensure travelers can easily move between distant regions without requiring numerous intermediate stops, which directly impacts the overall effectiveness and user experience of air travel. By analyzing the connectivity patterns and redundancy in airline networks, researchers seek to improve the design and operation of transportation infrastructure to enhance its performance metrics such as accessibility and robustness. [Source: article_1 (chunk 20)] [Source: article_1 (\n",
      "\n",
      "SOURCES: article_63, article_93, article_36, article_1\n",
      "================================================================================\n",
      "QUESTION:  How does a biased random walk differ from an unbiased random walk? \n",
      "\n",
      "ANSWER: A biased random walk differs from an unbiased random walk because it is influenced by the characteristics of neighboring nodes, which means that the movement of the walker is not purely random but rather guided by the properties of the nodes they encounter. This bias can lead to certain nodes being more frequently visited than others depending on the specific biasing function applied. In contrast, an unbiased random walk moves randomly without regard to the characteristics of the nodes, making it less predictable in terms of which nodes will be visited. The use of biased random walks allows for targeted exploration of a network, optimizing the path taken to achieve desired outcomes such as maximizing mixing or achieving a uniform distribution across all nodes. [Source: Article 1, chunk 2]\n",
      "\n",
      "The excerpt mentions \"degree-biased random walks\" specifically, indicating that these walks are designed to favor or avoid nodes based on their degree (number of connections). This type of biasing helps in defining new centrality measures, identifying communities within a network, and even guiding the exploration of a network using only local information. The concept of degree-biasing suggests that the randomness of the walk is influenced by the connectivity pattern of the nodes, leading to potentially more efficient exploration paths compared to standard random walks. [Source: Article\n",
      "\n",
      "SOURCES: article_63, article_93, article_36, article_1\n",
      "================================================================================\n",
      "QUESTION:  What is the role of entropy rate in characterizing a random walk? \n",
      "\n",
      "ANSWER: The entropy rate plays a crucial role in characterizing a random walk, particularly in understanding the information content or unpredictability associated with the movement of the walker through the network. It quantifies the amount of information gained about the next state of the system when observing the current state, reflecting the randomness and variability inherent in the process. In the context of random walks on complex networks, the entropy rate helps in assessing the efficiency and diversity of the path taken by the walker, providing insights into the exploration strategy employed by the walker across different layers of the network. This measure is essential for evaluating the effectiveness of various types of random walks, including those designed to maximize entropy or minimize heterogeneity in the stationary occupation probabilities, thereby guiding the choice of optimal strategies for traversing intricate structures. [Source: article_1 (chunk 23)]\n",
      "\n",
      "SOURCES: article_63, article_93, article_36, article_1\n",
      "================================================================================\n",
      "QUESTION:  Why are multi-layer networks considered more realistic than single-layer networks? \n",
      "\n",
      "ANSWER: Edge overlap refers to the degree to which edges connect nodes across different layers in a multi-layer network. It quantifies the extent to which nodes share connections with other nodes in adjacent layers, indicating the presence of cross-layer interactions. Higher edge overlap suggests greater connectivity between layers, implying that nodes in different layers\n",
      "\n",
      "SOURCES: article_63, article_1, article_141, article_93, article_36\n",
      "================================================================================\n",
      "QUESTION:  What does gauge invariance ensure in cosmological perturbation theory? \n",
      "\n",
      "ANSWER: Gauge invariance ensures that the evolution equations of the scalar modes of the vector field (a-modes) do not involve the scalar modes appearing in general relativity (gr-modes), which are associated to the metric and the energy momentum tensor of the cosmological fluids, but the a-modes modify the standard gauge-invariant equations describing the gr-modes. [Source: article_2 (chunk 4)]\n",
      "\n",
      "SOURCES: article_63, article_88, article_23, article_2, article_86, article_71, article_93, article_36\n",
      "================================================================================\n",
      "QUESTION:  How does edge overlap affect diffusion on multiplex networks? \n",
      "\n",
      "ANSWER: Edge overlap affects diffusion on multiplex networks by increasing the heterogeneity of the equilibrium occupation probability distribution, leading to potentially better performance for intensive random walkers compared to extensive ones. This is supported by findings showing that higher values of edge overlap result in a more heterogeneous stationary state probability distribution, indicating improved diffusion properties. [2]\n",
      "\n",
      "The relationship between edge overlap and diffusion can be understood through the concept of \"edge overlap\" being defined as the ratio of the total number of edges connecting any pair of nodes over the maximum possible number of edges. When this ratio is increased, it suggests that there are more redundant or overlapping connections within the network, which can enhance the flexibility and resilience of the system against disruptions. However, this redundancy may also lead to slower diffusion processes due to the potential inefficiency of using multiple pathways. The study mentioned in source [2] provides detailed insights into how different factors such as the number of layers, edge overlap, and inter-layer degree correlations influence the diffusion properties of random walkers on multiplex networks. [2]\n",
      "\n",
      "SOURCES: article_63, article_1, article_141, article_93, article_36\n",
      "================================================================================\n",
      "QUESTION:  How are extensive and intensive bias functions defined, and why do they differ in parameter scaling? \n",
      "\n",
      "ANSWER: Extensive bias functions are defined by their dependence on a function of the degrees of the destination node at each of the layers. This means that the number of parameters increases linearly with the number of layers, making them suitable for systems with many interdependent layers. In contrast, intensive bias functions depend on intrinsic multiplex properties of the destination node, which do not scale with the number of layers. Therefore, they offer a simpler tuning mechanism when aiming to achieve specific dynamical properties without increasing the complexity of the model. [Source: article_1 (chunk 3)] [Source: article_1 (chunk 11)]\n",
      "\n",
      "This distinction arises because extensive bias functions require adjusting multiple parameters across different layers, whereas intensive bias functions only need to adjust parameters related to the intrinsic properties of the node itself, regardless of how many layers there are. Thus, intensive bias functions are often preferred when dealing with models where the number of layers is large or variable, as it simplifies the optimization process. [Source: article_1 (chunk 11)] [Source: article_93 (chunk 26)] [Source: article_63 (chunk 5)]\n",
      "\n",
      "SOURCES: article_63, article_1, article_120, article_93, article_36\n",
      "================================================================================\n",
      "QUESTION:  In what way does the overlapping adjacency matrix differ from a simple aggregated network representation? \n",
      "\n",
      "ANSWER: The overlapping adjacency matrix differs from a simple aggregated network representation in several ways, including its ability to account for multiple edges between the same pair of nodes, which can lead to different patterns of connectivity compared to a simple aggregation approach. This allows for a more nuanced understanding of complex networks, such as those found in transportation systems, where redundant connections may enhance robustness against single link failures but also reduce the overall diffusivity and accessibility of the network. The overlapping adjacency matrix thus provides a richer description of the network structure, capturing both the direct and indirect connections between nodes, which is crucial for analyzing the dynamics of information or resources spread through the network. [1]\n",
      "\n",
      "[2] agrees, noting that while the overlapping adjacency matrix captures these redundancies, it comes at the cost of reduced diffusivity and increased heterogeneity in the equilibrium occupation probability distribution. This dual nature of the overlapping adjacency matrix reflects the trade-off between robustness and efficiency that is often sought in real-world transportation systems. [2]\n",
      "\n",
      "SOURCES: article_63, article_1, article_44, article_93, article_36\n",
      "================================================================================\n",
      "QUESTION:  How does inter-layer degree correlation influence the dispersiveness of biased random walks? \n",
      "\n",
      "ANSWER: The presence of degree-degree correlations in the structure of the network affects the dynamics of degree-biased random walks, leading to a stronger impact on their dispersiveness. This means that the preference for visiting nodes with higher degrees becomes more pronounced due to these correlations, resulting in a more concentrated distribution of visited nodes over time. The analysis presented in [1] shows how these correlations influence the phase diagram of biased random walks, indicating that they lead to a narrower range of line-of-maximum values, thereby affecting the overall dispersiveness of the process. [2] further elaborates on this point, emphasizing the importance of considering the specific nature of the correlations in determining the behavior of biased random walks within complex networks. [3] provides insights into constructing various types of biased random walks, including extensive and intensive walks, each characterized by distinct dependencies on the number of layers in the network, highlighting the role of layer-dependent biases in shaping the dispersiveness of these walks. These findings underscore the critical role of inter-layer correlations in modulating the dispersiveness of biased random walks across different network structures. [4] offers additional context by discussing the application of biased random walks in real-world scenarios, reinforcing the relevance of understanding how degree-degree correlations influence the performance of these\n",
      "\n",
      "SOURCES: article_63, article_93, article_36, article_1\n",
      "================================================================================\n",
      "QUESTION:  Why does the extended electromagnetic vector field introduce additional scalar modes in cosmology? \n",
      "\n",
      "ANSWER: The introduction of scalar modes in cosmology, according to the excerpt, arises because the extended electromagnetic vector field allows for the presence of scalar modes in the expansions of both the electromagnetic field (a-modes) and the current (j-modes). This is crucial in extending the understanding beyond standard electromagnetism, particularly in addressing the implications of the conservation laws within the context of cosmological models. The scalar modes enable a more comprehensive description of the dynamics in the universe, accommodating both vector and scalar contributions to the expansion process. [Source: article_2 (chunk 2)]\n",
      "\n",
      "SOURCES: article_63, article_93, article_36, article_2\n",
      "================================================================================\n",
      "QUESTION:  How do real-world multiplex airline networks demonstrate a trade-off between diffusion efficiency and robustness? \n",
      "\n",
      "ANSWER: Real-world multiplex airline networks evolve towards structures that balance efficient exploration and robustness. This is evident through studies showing that these networks exhibit high edge overlap, leading to lower maximal values of dispersiveness of the walk and larger heterogeneity in the equilibrium occupation probability distribution. The redundancy of edges in real-world networks enhances robustness against single link failures but comes at the cost of reduced diffusivity and increased heterogeneity in accessibilities. These findings align with the hypothesis that real-world transportation systems aim to satisfy a trade-off between providing high diffusivity and maintaining reasonable levels of robustness. [1][2]\n",
      "\n",
      "The authors also highlight that while the edge overlap of real-world systems is generally higher than that of null models, this does not necessarily imply a loss of efficiency or accessibility. Instead, they observe that the two multiplex networks with the smallest overlap and best diffusion properties still maintain superior performance compared to randomised systems. This suggests that the pursuit of robustness does come with a price in terms of dispersiveness and accessibility, yet the benefits in terms of efficient exploration outweigh these costs. [3][4][5]\n",
      "\n",
      "SOURCES: article_63, article_93, article_36, article_1\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Test Advanced RAG ---\n",
    "test_queries = [\n",
    "\" What is a random walk in the context of a network? \",\n",
    "\" What is meant by a multiplex (multi-layer) network? \",\n",
    "\" What does the term stationary probability distribution refer to? \",\n",
    "\" What are scalar perturbations in cosmology? \",\n",
    "\" What physical system do the airline transportation networks represent in the corpus? \",\n",
    "\n",
    "\" How does a biased random walk differ from an unbiased random walk? \",\n",
    "\" What is the role of entropy rate in characterizing a random walk? \",\n",
    "\" Why are multi-layer networks considered more realistic than single-layer networks? \",\n",
    "\" What does gauge invariance ensure in cosmological perturbation theory? \",\n",
    "\" How does edge overlap affect diffusion on multiplex networks? \",\n",
    "\n",
    "\" How are extensive and intensive bias functions defined, and why do they differ in parameter scaling? \",\n",
    "\" In what way does the overlapping adjacency matrix differ from a simple aggregated network representation? \",\n",
    "\" How does inter-layer degree correlation influence the dispersiveness of biased random walks? \",\n",
    "\" Why does the extended electromagnetic vector field introduce additional scalar modes in cosmology? \",\n",
    "\" How do real-world multiplex airline networks demonstrate a trade-off between diffusion efficiency and robustness? \"\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    print(f\"QUESTION: {q}\")\n",
    "    answer, sources = rag_answer(q, use_multi_query=True)\n",
    "    print(f\"\\nANSWER: {answer}\")\n",
    "    print(f\"\\nSOURCES: {', '.join(set(sources))}\")\n",
    "    print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-scientific-qa (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
